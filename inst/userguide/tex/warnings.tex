\chapter{Package MARSS:  Warnings and errors}
\label{app:warnings}
\index{troubleshooting}The following are brief descriptions of the warning and error messages you may see and what they mean (or might mean).  More warning information can be found by typing \verb@MARSSinfo()@ at the commmand line.

Over the years of helping people fit MARSS models, we have found that the most common problems arise when the MARSS model is inconsistent with the data. The following are common scenarios.
\begin{itemize}
\item The data do not remotely follow a Gaussian distribution. For example, they are binned data with long strings of one value.
\item The MARSS model being fit is stationary but the data are clearly non stationary.
\item The MARSS model being fit is non-stationary but the data are clearly stationary.
\item The initial conditions are impossible given the model or the data. For example, the initial conditions are fixed at 0 but data at $t=1$ is far from 0. Or the model implies that the initial state are correlated but a diagonal (= i.i.d.) initial condition variance-covariance matrix was used.
\item The MARSS model has a equilibrium mean level but the data are nowhere near that level and $\aa$ was set to zero so there is no way for the model to fit the data.
\item The data just do not look anything like an autoregressive process.
\item There isn't enough data to estimate both process and observation variances.
\item The user has designed a MARSS model with confounding parameters. Models with multiple confounded intercepts easy to design by accident.
\end{itemize}

\section*{B update is outside the unit circle}
\index{troubleshooting!B outside unit circle}If you are estimating $\BB$, then if the absolute value of all the eigenvalues of $\BB$ are less than 1, the system is stationary (meaning the $\XX$'s have some multivariate distribution that does not change over time).  In this case, we say that $\BB$ is within the unit circle.  A pure univariate random walk for example would have $\BB=1$ and it is not stationary.  The distribution of $\XX$ for the pure random walk has a variance that increases with time.  If on the other hand $|\BB|<1$, you have an Ornstein-Uhlenbeck process and is stationary, with a stationary variance of $\QQ/(1-\BB^2)$ (note $\BB$ is a scalar here because in this example $\XX$ is univariate).  If any of the eigenvalues (real part) are greater than 1, then the system will ``explode''---it rapidly diverges.

In the EM algorithm, there is nothing to force $\BB$ to be on or within the unit circle (real part of the eigenvalues less than or equal to 1).  It is possible at one of the EM iterations the $\BB$ update will be outside the unit circle.  The problem is that if you get too far outside the unit circle, the algorithm becomes numerically unstable since small errors are magnified by the ``explosive'' $\BB$ term.  If you see the `B outside the unit circle' warning, it is fine as long as it is temporary and the log-likelihood does not start decreasing (you will see a separate warning if that happens).

If you do see $\BB$ outside the unit circle and the log-likelihood decreases, then it probably means that you have poorly specified the model somehow.  An easy way to do this is to poorly specify the initial conditions, $\pipi$ and $\LAM$.  If, say, you try to specify a vague prior on $\xx_0$ (or $\xx_1$) with $\pipi$ equal to zero and $\LAM$ equal to a diagonal matrix with a large variance on the diagonal, you will likely run into trouble if $\BB$ has off-diagonal terms.  The reason is that by specifying that $\LAM$ is diagonal, you specified that the individual $X$'s in $\XX_0$ are independent, yet if $\BB$ has off-diagonal terms, the stationary distribution of $\XX_1$ is NOT independent.  If you force the diagonal terms on $\LAM$ to be big enough, you can force the maximum-likelihood estimate of $\BB$ to be outside the unit circle since this is the only way to account for $\XX_0$ independent and $\XX_1$ highly correlated\index{prior!troubleshooting}.  

The problem is that you will not know the stationary distribution of the $\XX$'s (from which $\XX_0$ was presumably drawn) without knowing the parameters you are trying to estimate.  One approach is the estimate both $\pipi$ and $\LAM$ by setting \verb@x0="unconstrained"@ and \verb@V0="unconstrained"@ in the model specification.  Estimating both $\pipi$ and $\LAM$ cannot be done robustly for all MARSS models, and in general, one probably wants to specify the model in such a way as to fix one or both of these.   Another, more robust approach, is to treat $\xx_1$ as fixed but unknown (instead of $\xx_0$).  You do this by setting \verb@model$tinitx=1@, so that $\pipi$ refers to $t=1$ not $t=0$.  Then estimate $\pipi$ and fix $\LAM=0$. This eliminates $\LAM$ from the model and often eliminates the problems with prior specification---as the expense of $m$ more parameters.  Note, when you set $\LAM=0$, $\LAM$ is truly eliminated from the model; the likelihood function is different, so do not expect $\LAM=0$ and $\LAM \sim 0$ to have the same likelihood under all conditions.

\section*{Warning! Reached maxit before parameters converged}
\index{troubleshooting!non-convergence}The maximum number of EM iterations is set by \verb@control$maxit@.  If you get this warning, it means that one of the parameters or log-likelihood had not yet reached the convergence stopping criteria before \verb@maxit@ was reached.  There are many situations where you might want to set \verb@control$maxit@ lower than the value needed to reach convergence.  For example, if you are using the EM algorithm to produce initial values for a different algorithm (like a Bayesian MCMC algorithm or a Newton method) then you can set \verb@maxit@ low, say 20 or 50.

\section*{Stopped at iter=xx in MARSSkem() because numerical errors were generated in MARSSkf}
\index{troubleshooting!numerical instability}This means the Kalman filter/smoother algorithm became unstable and most likely one of the variances became ill-conditioned.  When that happens the inverses of those matrices are poor, and you will start to get negative values on the diagonals of your variance-covariance matrices.  Once that happens, the inverse of that variance-covariance matrix produces an error.  If you get this error, turn on tracing with \verb@control$trace=1@. This will store the error messages so you can see what is going on.  It may be that you have specified the model in such a way that some of the variances are being forced very close to 0, which makes the variance-covariance matrix ill-conditioned.  The output from the MARSS call will be the parameter values just before the error occurred.

\section*{Warning: the  xyz  parameter value has not converged}
\index{troubleshooting!non-convergence}The algorithm checks whether the log-likelihood and each individual parameter has converged.  If a parameter has not converged, you can try upping \verb@control$maxit@ and see if it converges.  If you set, \verb@maxit@ high, but the parameter is still not converging, then it suggests that one of the variance parameters is so small that the EM update steps for that parameter are tiny.  For example, as $\QQ$ goes to zero, the update steps for $\uu$ go to zero.  As $\LAM$ goes to zero, the update steps for $\pipi$ go to zero.  The first thing to do is to reflect on whether you are inadvertently specifying the model in such a way that one of the variances is forced to zero.  For example, if the total variance in $\XX$ is 0.1 and you fix $\RR=0.2$ then $\QQ$ must go to zero.  The second thing to do is to try using a Newton algorithm, using your last EM values as the initial conditions for the Newton algorithm.  The initial values are set using the \verb@inits@ argument for the \verb@MARSS()@ function.  

\section*{MARSSkem: The solution became unstable and logLik DROPPED}
\index{troubleshooting!numerical instability}\index{troubleshooting!logLik dropped}This is a more serious error as in the EM algorithm, the log-likelihood should never drop.  The first thing to do is check if you have specified a bizarre model or data, inadvertently.  Plot the data you are trying to fit.  Often, this error arises when a user has inadvertently scrambled their data order during a demeaning or variance-standardization step.  Second, check the model you are trying to fit.  Use \verb@test=MARSS(data, model=xyz, fit=FALSE)@ and then \verb@summary(test$model)@.  This shows you what \verb@MARSS()@ thinks your model is.  You may be trying to fit an illogical model.

If those checks looks good, then pass \verb@control$trace=1@ into the \verb@MARSS()@ call.  This will report a fuller set of warnings.  Look if the error ``B is outside the unit circle'' appears.  If so, you are probably specifying a strange $\BB$ matrix.  Are you forcing the $\BB$ matrix to be outside the unit circle (eigenvalues > 1)? If so, you need to rethink your $\BB$ matrix constraints.  If you do not see that error, look at \verb@test$iter.record$logLik@.  If the log-likelihood is steadily dropping (at each iteration) or drops by large amounts (much larger than the machine precision), that is bad and means that the EM algorithm did not work.  If however the log-likelihood is just fluctuating by small amounts about some steady value, that is ok as it means that the values converged but the parameters are such that there are slight numerical fluctuations.  Try passing \verb@control$safe=TRUE@ in the \verb@MARSS()@ call. This can sometimes help as it inserts a call to the Kalman filter after each individual parameter update.

\section*{Stopped at iter=xx in MARSSkem: solution became unstable. R (or Q) update is not positive definite}
\index{troubleshooting!matrix not positive definite}First check if you have specified an illegally constrained variance-covariance matrix.  For example, if the variances (diagonal) are constrained to be equal, you cannot specify the covariances (off-diagonals) as unequal. Or if you specify that some of the covariances are equal, you cannot specify the variances as all unequal.  These are illegal constraints on a variance-covariance matrix from a statistical perspective (nothing to do with \{MARSS\} package functions specifically).

This could also be due to numerical instability as $\BB$ leaves the unit circle or one of the variance matrix becomes ill-conditioned.  Try turning on tracing with \verb@control$trace=1@ and turn on safe with \verb@control$safe=TRUE@.  This will print out the error warnings at each parameter update step.  Then consider whether you have inadvertently specified the model in such a way as to force this behavior in the $\BB$ parameter.

You might also get this error if you inadvertantly specified an improper structure for $\RR$ or $\QQ$.  For example, if you used \verb@R=diag(c(1,1,"r"))@ with the intent of specifying a diagonal matrix with fixed variance 1 at $\RR[1,1]$ and $\RR[2,2]$ and an estimated $\RR[3,3]$, you would have actually specified a character matrix with \verb@"0"@ on the off-diagonals and \verb@c("1","1","r")@ on the diagonal.  \verb@MARSS()@ interprets all elements in quotes as names of parameters to be estimated.  Thus it will estimate one off-diagonal covariance and two diagonal variances.  That happens to put illegal constraints on estimation of a variance-covariance matrix having nothing to do with the \verb@MARSS()@ function but with estimation of variance-covariance matrices in general. 

\section*{iter=xx MARSSkf: logLik computation is becoming unstable.  Condition num. of Sigma[t=1] = Inf and of R = Inf.}
\index{troubleshooting!sigma condition number}This means, generally, that \verb@V0@ ($\LAM$) is very small, say 0, and $\RR$ diagonal elements are very small and very close to zero.

\section*{ Warning: setting diagonal to 0 blocked at iter=X. logLik was lower in attempt to set 0 diagonals on X }
\index{troubleshooting!setting diagonal to 0 blocked}This is a warning not an error.  What is happening is that one of the variances (in $\QQ$ or $\RR$) is getting small and the EM algorithm is attempting to set the value to 0 (because \verb@control$degen.allow=TRUE@).  But when it tried to do this, the new likelihood with the variance equal to 0 was lower and the variance was not set to 0. 

A model with a variance minuscule and a model with the same variance equal to 0 are not the same model\index{prior!troubleshooting}.  In the first, a stochastic process with small variance exists but in the second, the analogous process is deterministic.  And in the first case, you can get a situation where the likelihood term L(x|mean=mu,sigma=0) appears.  That term will be infinite when x=mu. So in the model with variance minuscule, you will get very large likelihood values as the variance term gets smaller and smaller.  In the analogous model with that variance set to 0, that likelihood term does not appear so the likelihood does not go to infinity.  

This is not an error nor pathological behavior; the models are fundamentally different.  Nonetheless, this will pose a dilemma when you want to chose the best model based on maximum likelihood.  The model with minuscule variance will have infinite likelihood but the same behavior as the one with variance 0.   In our experience, this dilemma arises when one has a lot of missing data near the beginning of the time series and is affected by how you specify the prior on the initial state.  Try setting the prior at $t=0$ versus $t=1$.  Try using a diffuse prior.  You absolutely want to compare estimates using the BFGS and EM algorithms in this case, because the different algorithms differ in their ability to find the maximum in this strange case.  Neither is uniformly better or worse.  It seems to depend on which variance ($\QQ$ or $\RR$) is going to zero.

\section*{Warning: kf returned error at iter=X in attempt to set 0 diagonals for X}
\index{troubleshooting!Kalman filter errors}This is a warning that the EM algorithm tried to set one of the diagonals of element X to 0 because \verb@allow.degen@ is TRUE and element X is going to zero.  However when this was tried, the Kalman filter returned an error.  Typically, this happens when both $\RR$ and $\QQ$ elements are both trying to be set to 0.  If the maximum-likelihood estimate is that both $\RR$ and $\QQ$ are zero, it probably means that your MARSS model is not a very good description of the data.

\section*{Warning: At iter=X attempt to set 0 diagonals for R blocked for elements where corresponding rows of A or Z are not fixed. }
\index{troubleshooting!setting diagonal to 0 blocked}You have \verb@control$degen.allow=TRUE@ and one of the $\RR$ diagonal elements is getting very small.  \{MARSS\} attempts to set these $\RR$ elements to 0, but if row $i$ of $\RR$ is 0, then the corresponding $i$ rows of $\aa$ and $\ZZ$ must be fixed.  This is for the EM algorithm.  It might work with the BFGS algorithm, or might spit out garbage without warning you.  Always be suspicious when the EM and BFGS behavior is different.  That is a good sign that something is wrong with how your model describes the data.  It's not a problem with the algorithms per se; rather for certain pathological models, the algorithms behave differently from each other.

\section*{Stopped at iter=X in MARSSkem. XYZ is not invertible.  }
\index{troubleshooting!matrix not invertible}There are a series of checks in \{MARSS\} that check if matrix inversions are possible before doing the inversion.   These errors crop up most often when $\QQ$ or $\RR$ are getting very small.  At some point, they can get so small that inversions become unstable.  If this error is given, then the output will be the last parameter estimates before the error.  Try setting \verb@control$allow.degen=FALSE@.  Sometimes the error occurs when a diagonal element of $\QQ$ or $\RR$ is being set to 0.  You will also have to set \verb@control$maxit@ to something smaller because the EM algorithm will not stop since the problematic diagonal element will walk slowly and inexorably to 0.  
