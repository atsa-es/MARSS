\SweaveOpts{keep.source=TRUE, prefix.string=./figures/MCI-, eps=FALSE, split=TRUE}
<<RUNFIRST, echo=FALSE, include.source=FALSE>>=
library(MARSS)
options(prompt = " ", continue = " ", width = 60)
@

\chapter{Setting and searching initial conditions}
\label{chap:inits}
\chaptermark{Setting inits}\index{initial conditions}
\index{initial conditions}
%Add footnote with instructions for getting code
\blfootnote{Type \texttt{RShowDoc("Chapter\_inits.R",package="MARSS")} at the R command line to open a file with all the code for this chapter and see a copy of the old \texttt{MARSSmcinit()} function.}
The EM algorithm is very robust to initial starting conditions however before final results are accepted, they should be tested using other initial conditions. Other times you will want to pass in specific initial conditions because the \verb@MARSS()@ function cannot find initial conditions on its own, which is the case for certain models with certain $\ZZ$ matrices in particular or you might want to start with initial conditions at the MLEs of another fit.  This chapter shows you how to set initial conditions.

The chapter will also cover using a Monte Carlo search over random initial values.  This is a brute force method for finding optimal initial conditions.  It simply uses random initial conditions and runs the EM algorithm for a number of iterations and selects the initial conditions with the highest log-likelihood after the given number of iterations.  In MARSS versions 3.9 and earlier, there was a utility function to perform a Monte Carlo search.  However, it is very hard for the function to come up with reasonable random initial conditions for the wide variety of models that MARSS can fit.  In MARSS version 3.10, the \verb@MARSSmcinit()@ function was removed and replaced with this chapter discussing how to do your own Monte Carlo initial conditions search.  The original \verb@MARSSmcinit()@ function is included in the R code with this chapter (see footnote). 

\section{Fitting a model with a new set of initial conditions}
\index{initial conditions!specifying}
Fitting a model with a new set of initial conditions is straight-forward with the \verb@MARSS()@ function.  Simply pass in the argument \verb@inits@.  This is illustrated with an example from Chapter \ref{chap:covariates}.

We will fit a model with covariates to phytoplankton data:
<<Cs_mci_001>>=
fulldat <- lakeWAplanktonTrans
years <- fulldat[, "Year"] >= 1965 & fulldat[, "Year"] < 1975
dat <- t(fulldat[years, c("Greens", "Bluegreens")])
the.mean <- apply(dat, 1, mean, na.rm = TRUE)
the.sigma <- sqrt(apply(dat, 1, var, na.rm = TRUE))
dat <- (dat - the.mean) * (1 / the.sigma)
@

The covariates for this example are temperature and total phosphorous.
<<Cs_mci_002>>=
covariates <- rbind(
  Temp = fulldat[years, "Temp"],
  TP = fulldat[years, "TP"]
)
# demean the covariates
the.mean <- apply(covariates, 1, mean, na.rm = TRUE)
covariates <- covariates - the.mean
@

We will fit a model where algal abundance is a random walk without drift and where the observation errors are explained by the covariates plus independent unexplained noise:
<<Cs_mci_003>>=
U <- x0 <- "zero"
Q <- "unconstrained"
d <- covariates
A <- "zero"
D <- "unconstrained"
R <- "diagonal and equal"
model.list <- list(
  U = U, Q = Q, A = A, R = R,
  D = D, d = d, x0 = x0
)
kem <- MARSS(dat, model = model.list)
@

The \verb@inits@ argument can  be set either as a list that is the same as that from the following:
<<Cs_mci_004, results=hide>>=
coef(kem, what = "par")
@
or as a marssMLE object from previous \verb@MARSS()@ call for a model with the same structure.  `same structure' means the model list used for the \verb@model@ argument is the same and the dimensions of the model (number of states and rows of data) are the same.

\subsection{Specifying initial conditions as a list}
The output from \verb@coef(kem, what="par")@ is a list with a column vector of the estimated values for each parameter matrix.  Here is the value for $\DD$ and $\QQ$:
<<Cs_mci_005>>=
out <- coef(kem, what = "par")
out$D
out$Q
@
\verb@MARSS()@ gave names to the $\DD$ and $\QQ$ estimated values.  It is important to look at the output from \verb@coef(..., what="par")@ before passing in the inits list so that you know where the parameter values fall in the parameter column vector.  For example, note that in the $\QQ$ column vector, the variance for the first row in $\xx$ (Greens) is first, the (1,1) element, then the covariance, and last value is the variance of the second row in $\xx$ (Bluegreens) which appears in the (2,2) element of $\QQ$.

You can pass in \verb@inits@ for any of the parameters in \verb@coef(..., what="par")@.  You can pass in either a column vector that is the same size as that output by \verb@coef()@, so for $\QQ$, the column vectors must be $3 \times 1$, or a scalar.  If a scalar, then all values in the par column vector will be set to that value---except for $\QQ$, $\RR$ and $\LAM$ which will be set to diagonal matrices with the scalar on the diagonal.

\subsubsection{Examples}
Pass in an initial value for $\QQ$ that is a diagonal matrix with 1 on the diagonal.
<<Cs_mci_006, keep.source=TRUE>>=
inits <- list(Q = 1)
kem <- MARSS(dat, model = model.list, inits = inits)
# or
inits <- list(Q = matrix(c(1, 0, 1), 3, 1))
kem <- MARSS(dat, model = model.list, inits = inits)
@

Pass in an initial value for $\QQ$ that is this non-diagonal matrix:
$$\begin{bmatrix}1&0.5\\0.5&0.7\end{bmatrix}$$
<<Cs_mci_007, results=hide>>=
inits <- list(Q = matrix(c(1, 0.5, 0.7), 3, 1))
kem <- MARSS(dat, model = model.list, inits = inits)
@

Pass in an initial value for $\QQ$ and $\DD$:
<<Cs_mci_008, results=hide>>=
inits <- list(Q = matrix(c(1, 0.5, 0.7), 3, 1), D = 1)
kem <- MARSS(dat, model = model.list, inits = inits)
@
The initial values for $\DD$ will be all 1s.

Pass in an initial value for $\DD$ set to the value from a previous fit but use default \verb@inits@ for everything else:
<<Cs_mci_009, results=hide>>=
inits <- list(D = coef(kem, what = "par")$D)
kem <- MARSS(dat, model = model.list, inits = inits)
@

\subsection{Specifying initial conditions  using output from another fit}
\index{initial conditions!using another fit}
You can also use a \verb@MARSS()@ fit as an initial condition.  The model must be the same structure.  This is typically used when you want to use an EM fit as a start for a BFGS fit if you are using BFGS for the final MLE search.

You can pass in the initial conditions as a list using the \verb@coef()@ function.
<<Cs_mci_010, results=hide>>=
# create the par list from the output
inits <- coef(kem, what = "par")
bfgs <- MARSS(dat, model = model.list, inits = inits, method = "BFGS")
@
Or you can pass in a marssMLE object output from a prior call to \verb@MARSS()@. This is a shortcut for the above call.
<<Cs_mci_0101, results=hide>>=
# create the par list from the output
bfgs <- MARSS(dat, model = model.list, inits = kem, method = "BFGS")
@

\section{Searching across initial values using a Monte Carlo routine}
\index{initial conditions!Monte Carlo search}
The EM algorithm is a hill-climbing algorithm and like all hill-climbing algorithms it can get stuck on local maxima and ridges.  There are a number approaches to doing a pre-search of the initial conditions space, but a brute force  random Monte Carlo search appears to work well \citep{Biernackietal2003}.  It is slow, but normally sufficient.  In our papers on the distributional properties of  MARSS parameter estimates, we rarely found that an initial conditions search changed the estimates---except in cases where $\ZZ$ and $\BB$ are estimated as unconstrained or when the fraction of missing data in the data set became large.  Regardless an initial conditions search should be done before reporting final estimates for an analysis\footnote{It is also a good idea to try \texttt{method="BFGS"} to see if this changes the estimates.}.  

The idea behind a Monte Carlo search of initial conditions is simple.  One simply randomly generates initial conditions, runs the EM algorithm a few iterations (10-20), and saves the log-likelihood at the end of those iterations.  The starting initial conditions is selected as the initial conditions that gives the lowest log-likelihood. 

The R code included for this chapter includes a function that will do a simple Monte Carlo search using a marssMLE object (output from a \verb@MARSS()@ call) and drawing random initial conditions from a uniform distribution or a Wishart distribution for the variance-covariance matrices. The function will not work for all MARSS models but will give you a starting point for setting up your own Monte Carlo search.  The function uses a control list to set \texttt{numInits}, the number of random initial value draws, \texttt{numInitSteps}, the maximum number of EM iterations for each random initial value draw, and \texttt{boundsInits}, the bounds for the random distributions. It outputs a list with specifying the initial values that give the lowest log-likelihood.

<<Cs_mci_011, echo=FALSE>>=
######################################################################################################   MARSSmcinit function
#   Does a simple MonteCarlo initialization of the EM routine
#   The function uses a number of MARSS utility functions accessed with MARSS:::
#######################################################################################################
MARSSmcinit <- function(MLEobj,
                        control = list(
                          numInits = 500, numInitSteps = 10,
                          MCbounds = list(
                            B = c(0, 1), U = c(-1, 1), Q = c(1, 1),
                            Z = c(0, 1), A = c(-1, 1), R = c(1, 1), x0 = c(-1, 1)
                          )
                        ),
                        silent = FALSE) {
  control.default <- list(numInits = 500, numInitSteps = 10, MCbounds = list(B = c(0, 1), U = c(-1, 1), Q = c(1, 1), Z = c(0, 1), A = c(-1, 1), R = c(1, 1), x0 = c(-1, 1)))
  if (!is.null(control)) {
    if (!is.list(control)) stop("MARSSmcinit: control must be a list")
    if (any(!(names(control) %in% names(control.default)))) stop(paste("MARSSmcinit: allowed control list elements are", names(control.default)))
    control.new <- control.default
    for (i in names(control)) control.new[[i]] <- control[[i]]
    control <- control.new
  }
  drawProgressBar <- FALSE
  if (!silent) { # then we can draw a progress bar
    cat("\n")
    cat("> Starting Monte Carlo Initializations\n")
    prev <- MARSS:::progressBar() # this is an internal function to MARSS
    drawProgressBar <- TRUE
  }
  MODELobj <- MLEobj[["marss"]]
  y <- MODELobj$data
  par.dims <- attr(MODELobj, "model.dims")
  m <- par.dims[["x"]][1]
  n <- par.dims[["y"]][1]
  TT <- par.dims[["data"]][2]
  ## YM matrix for handling missing values
  YM <- matrix(as.numeric(!is.na(y)), n, TT)
  # Make sure the missing vals in y are zeroed out
  y[YM == 0] <- 0

  free.tmp <- MODELobj$free
  dim.tmp <- list(Z = c(n, m), A = c(n, 1), R = c(n, n), B = c(m, m), U = c(m, 1), Q = c(m, m), x0 = c(m, 1))
  bounds.tmp <- control$MCbounds
  init <- bestinits <- MLEobj$start
  bestLL <- -1.0e10

  # loop over numInits: # of random draws of initial values
  for (loop in 1:control$numInits) {
    init.loop <- init

    # Draw random values
    en <- c("Z", "A", "R", "B", "U", "Q", "x0")
    for (el in en) {
      dim.param <- dim.tmp[[el]]
      if (!MARSS:::is.fixed(free.tmp[[el]])) { # is.fixed is a utility func in MARSS
        bounds.param <- bounds.tmp[[el]]
        # use the first fixed and free in a temporally varying model; arbitrary
        tmp <- list(f = MARSS:::sub3D(MODELobj$fixed[[el]], t = 1), D = MARSS:::sub3D(MODELobj$free[[el]], t = 1))
        if (el %in% c("Q", "R")) { # random starts drawn from a wishart dist
          if (bounds.param[1] < dim.param[1]) {
            df <- dim.param[1]
          } else {
            df <- bounds.param[1]
          }
          S <- diag(bounds.param[2], dim.param[1])
          # draw a random matrix from wishart
          tmp.random <- MARSS:::rwishart(df, S) / df
          # reapply the sharing and fixed constraints
          par.random <- solve(t(tmp$D) %*% tmp$D) %*% t(tmp$D) %*% (MARSS:::vec(tmp.random) - tmp$f)
        } else {
          par.random <- matrix(runif(dim(tmp$D)[2], bounds.param[1], bounds.param[2]), dim(tmp$D)[2], 1)
          if (el %in% c("B")) {
            tmp.max <- max(abs(eigen(par.random, only.values = TRUE)$values))
            # rescale to bring the max abs eigenvalues to between 0 and 1
            par.random <- par.random / (tmp.max / runif(1, .01, .99))
          }
          if (el %in% c("x0")) {
            x0init <- init$x0 # where the original start is
            x.lo <- ifelse(x0init > 0, exp(bounds.param[1]) * x0init, exp(bounds.param[2]) * x0init)
            x.hi <- ifelse(x0init > 0, exp(bounds.param[2]) * x0init, exp(bounds.param[1]) * x0init)
            par.random <- matrix(runif(dim(tmp$D)[2], x.lo, x.hi), dim(tmp$D)[2], 1)
          }
        }
      } else {
        par.random <- matrix(0, 0, 1)
      }
      init.loop[[el]] <- par.random
    }

    ## Call MARSSkem() with these inits
    MLEobj$start <- init.loop
    MLEobj$control$maxit <- control$numInitSteps
    MLEobj$control$minit <- 1
    MLEobj$control$silent <- TRUE # don't output
    MLEobj <- MARSSkem(MLEobj) # get new fit using this init

    if (drawProgressBar == TRUE) prev <- MARSS:::progressBar(loop / control$numInits, prev)

    ## Check whether the likelihood is the best observed
    ## Only use bootstrap param draws where loglike did not go down during numInitSteps
    if (MLEobj$logLik > bestLL) {
      # update the best initial parameter estimates
      bestinits <- MLEobj$par
      bestLL <- MLEobj$logLik
    }
  } # end numInits loop

  return(bestinits)
}
@

Here is a simple example of using the function.  \verb@numInits@ is set low so that the example runs quickly.
<<Cs_mci_012>>=
dat <- t(harborSeal)
dat <- dat[c(2, nrow(dat)), ]
fit1 <- MARSS(dat)
MCinits <- MARSSmcinit(fit1, control = list(numInits = 10))
fit2 <- MARSS(dat, inits = MCinits)
@

<<reset, echo=FALSE, include.source=FALSE>>=
options(prompt = "> ", continue = " +", width = 120)
@
