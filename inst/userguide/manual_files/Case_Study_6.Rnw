\SweaveOpts{keep.source=TRUE, prefix.string=./figures/CS6-, eps=FALSE, split=TRUE}
\chapter{Detection of outliers and structural breaks}
\label{chap:CSstrucbreak}
\chaptermark{Outliers and structural breaks}
<<RUNFIRST, echo=FALSE, include.source=FALSE>>=
options(prompt = " ", continue = " ")
tabledir <- "tables/"
@

%Add footnote with instructions for getting code
\blfootnote{Type \texttt{RShowDoc("Chapter\_StructuralBreaks.R",package="MARSS")} at the R command line to open a file with all the code for the examples in this chapter.}

\section{Background}
\index{structural breaks}\index{outliers} This chapter is based on a short example shown on pages 147-148 in \citet{Koopmanetal1998} using a 100-year record of river flow on the Nile River.  The methods are based on \citet{Harveyetal1998} which is in turn based on techniques in \citet{HarveyKoopman1992} and \citet{Koopman1993}. The Nile dataset is included in \R.  Figure \ref{fig:CS6.fig1} shows the data.

<<Cs00_required_packages, echo=FALSE>>=
library(MARSS)
library(xtable)
library(survival)
library(Formula)
library(ggplot2)
library(Hmisc)
library(datasets)
@



\begin{figure}[htp]
\begin{center}
<<Cs01_plotdata, eval=TRUE, echo=TRUE, fig=TRUE>>=
# load the datasets package
library(datasets)
data(Nile) # load the data
plot(Nile, ylab = "Flow volume", xlab = "")
@
\end{center}
\caption{The Nile River flow volume 1871 to 1970 (included dataset in \R).}
\label{fig:CS6.fig1}
\end{figure}

\section{Different models for the Nile flow levels}
We begin by fitting different flow models to the data and compare these models with AIC.  After that, we will use the model residuals to look for outliers and structural breaks.\index{structural ts model!univariate}\index{structural ts model!Nile}

\subsection{Flat level model}
We will start by modeling these data as a simple average river flow with variability around this level.  
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
y_t = a+v_t \text{ where } v_t \sim \N(0,r)    
 \label{eq:simple.model}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
where $y_t$ is the river flow volume at year $t$ and $x$ is some constant average flow level (notice it has no $t$ subscript).

To fit this model with MARSS, we will explicitly show all the MARSS parameters.
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = 1 \times x_{t-1}+ 0 + w_t    \text{ where } w_t \sim \N(0,0) \\
y_t = 0 \times x_t + a + v_t \text{ where } v_t \sim \N(0,r)  \\
x_0 = 0 
 \end{gathered}   
 \label{eq:marss.model}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
MARSS includes the state process $x_t$ but we are setting $\ZZ$ to zero so that does not appear in our observation model.  We need to fix all the state parameters to zero so that the algorithm doesn't ``chase its tail'' trying to fit $x_t$ to the data.

An equivalent way to write this model is to use $x_t$ as the average flow level and make it be a constant level by setting $q=0$.  The average flow appears as the $x_0$ parameter.  Written as a MARSS model, the model is:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = 1 \times x_{t-1}+ 0 + w_t    \text{ where } w_t \sim \N(0,0) \\
y_t = 1 \times x_t + 0 + v_t \text{ where } v_t \sim \N(0,r)  \\
x_0 = a 
 \end{gathered}   
 \label{eq:marss.model.0}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
We will use this latter format since we will be building on this form.  The model is specified as follows:
<<Cs02_mod-nile-0, eval=TRUE>>=
mod.nile.0 <- list(
  Z = matrix(1), A = matrix(0), R = matrix("r"),
  B = matrix(1), U = matrix(0), Q = matrix(0),
  x0 = matrix("a")
)
@

We then fit the model:
<<Cs03_fit-data-0, eval=TRUE>>=
# The data is in a ts format, and we need a matrix
dat <- t(as.matrix(Nile))
rownames(dat) <- "Nile"

kem.0 <- MARSS(dat, model = mod.nile.0, silent = TRUE)
summary(kem.0)
@

\subsection{Linear trend in flow model}
Figure \ref{fig:CS6.fits} shows the fit for the flat average river flow model.  Looking at the data, we might expect that a declining average river flow would be better.  In MARSS form, that model would be:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = 1 \times x_{t-1}+ u + w_t    \text{ where } w_t \sim \N(0,0) \\
y_t = 1 \times x_t + 0 + v_t \text{ where } v_t \sim \N(0,r)  \\
x_0 = a 
\end{gathered}   
\label{eq:marss.model.1}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
where $u$ is now the average per-year decline in river flow volume.  The model is specified as  follows:
<<Cs04_mod-nile-1, eval=TRUE>>=
mod.nile.1 <- list(
  Z = matrix(1), A = matrix(0), R = matrix("r"),
  B = matrix(1), U = matrix("u"), Q = matrix(0),
  x0 = matrix("a")
)
@

We then fit the model:
<<Cs05_fit-data-1, eval=TRUE>>=
kem.1 <- MARSS(dat, model = mod.nile.1, silent = TRUE)
summary(kem.1)
@
Figure \ref{fig:CS6.fits} shows the fits for the two models with deterministic models (flat and declining) for mean river flow along with their AICc values (smaller AICc is better).    The AICc for the model with a declining river flow is lower by over 20 (which is a lot).

\subsection{Stochastic level model}
Looking at the flow levels, we might suspect that a model that allows the average flow to change would model the data better and we might suspect that there have been sudden, and anomalous, changes in the river flow level.
We will now model the average river flow at year $t$ as a random walk, specifically an autoregressive process which means that average river flow in year $t$ is a function of the average river flow in year $t-1$.  
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = x_{t-1}+w_t \text{ where } w_t \sim \N(0,q) \\
y_t = x_t+v_t \text{ where } v_t \sim \N(0,r)  \\
x_0 = \pi 
\end{gathered}   
\label{eq:random.walk.w.noise}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
As before, $y_t$ is the river flow volume at year $t$.  With all the MARSS parameters shown, the model is:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = 1 \times x_{t-1}+ 0 + w_t    \text{ where } w_t \sim \N(0,q) \\
y_t = 1 \times x_t + 0 + v_t \text{ where } v_t \sim \N(0,r)  \\
x_0 = \pi 
 \end{gathered}   
 \label{eq:marss.model.2}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
Thus, $\ZZ=1$, $\aa=0$, $\RR=r$, $\BB=1$, $\uu=0$, $\QQ=q$, and $\xx_0=\pi$.  The model is then specified as:
<<Cs06_mod-nile-2, eval=TRUE>>=
mod.nile.2 <- list(
  Z = matrix(1), A = matrix(0), R = matrix("r"),
  B = matrix(1), U = matrix(0), Q = matrix("q"),
  x0 = matrix("pi")
)
@
We could also use the text shortcuts to specify the model.  Because $\RR$ and $\QQ$ are $1 \times 1$ matrices, ``unconstrained'', ``diagonal and unequal``, ``diagonal and equal'' and ``equalvarcov'' will all lead to a $1 \times 1$ matrix with one estimated element.

To fit the model, we use the BFGS algorithm to polish off the estimates, since it will get the maximum faster than the default EM algorithm as long as we start it close to the maximum.
<<Cs07_fit-data-2, eval=TRUE>>=
kem.2em <- MARSS(dat, model = mod.nile.2, silent = TRUE)
kem.2 <- MARSS(dat,
  model = mod.nile.2,
  inits = kem.2em$par, method = "BFGS", silent = TRUE
)
summary(kem.2)
@
This is the same model fit in \citet[p. 148]{Koopmanetal1998} except that we estimate $x_1$ as parameter rather than specifying $x_1$ via a diffuse prior\index{prior!diffuse}. As a result, the log-likelihood value and $\RR$ and $\QQ$ are a little different than in  \citet{Koopmanetal1998}. 

\begin{comment}

To fit the model as Koopman et al. did, use the following specifications:  
<<fit-data-koop, eval=TRUE>>=
mod.nile.3 <- list(
  Z = matrix(1), A = matrix(0), R = matrix("r"),
  B = matrix(1), U = matrix(0), Q = matrix("q"),
  x0 = matrix("pi"), tinitx = 1, diffuse = TRUE
)
# kem.3.koop=MARSS(dat, model=mod.nile.3,
#  inits=kem.2em$par, method="BFGS")
@
The \verb@model$diffuse=TRUE@\index{prior!diffuse} specification means to use a true diffuse prior (variance is infinite).

\end{comment}

\begin{figure}[htp]
\begin{center}
<<Cs08_plotfit, eval=TRUE, echo=FALSE, fig=TRUE, width=5, height=6>>=
library(Hmisc)
par(mfrow = c(3, 1), mar = c(4, 4, 0.5, 0.5), oma = c(1, 1, 1, 1))
x <- seq(tsp(Nile)[1], tsp(Nile)[2], tsp(Nile)[3])
# model 0
plot(Nile, ylab = "Flow volume", xlab = "", xaxp = c(1870, 1970, 10), bty = "L")
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
kem <- kem.0 # model 0 results
lines(x, kem$states[1, ], col = "red", lwd = 2)
legend("topright", paste("model 0, AICc=", format(kem.0$AICc, digits = 1)), bty = "n")

# model 1
plot(Nile, ylab = "Flow volume", xlab = "", xaxp = c(1870, 1970, 10), bty = "n")
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
kem <- kem.1 # model 1 results
lines(x, kem$states[1, ], col = "red", lwd = 2)
legend("topright", paste("model 1, AICc=", format(kem.1$AICc, digits = 1)), bty = "n")

# model 2
plot(Nile, ylab = "Flow volume", xlab = "", xaxp = c(1870, 1970, 10), bty = "L")
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
kem <- kem.2 # model 0 results
lines(x, kem$states[1, ], col = "red", lwd = 2)
lines(1871:1970, kem$states[1, ] - 2 * kem$states.se[1, ], col = "red", lty = 2)
lines(1871:1970, kem$states[1, ] + 2 * kem$states.se[1, ], col = "red", lty = 2)
legend("topright", paste("model 2, AICc=", format(kem$AICc, digits = 1)), bty = "n")
@
\end{center}
\caption{The Nile River flow volume with the model estimated flow rates (solid lines).  The bottom model is a stochastic level model, and the 2 standard deviations for the level are also shown.  The other two models are deterministic level models so the state is not stochastic and does not have a standard deviation.}
\label{fig:CS6.fits}
\end{figure}

\section{Observation and state residuals}
\index{residuals!auxiliary}\index{residuals!smoothations}
Figure \ref{fig:CS6.fits} shows the fits to the data.  From these model fits, auxiliary residuals can be computed which contain information about whether the data and models fits at time $t$ differ more than you would expect given the model and the model fits at time $t-1$.  In this section, we follow the example shown on page 147-148 in \citet{Koopmanetal1998} and use these residuals to look for outliers and sudden flow level changes.  Using auxiliary residuals this way follows mainly from \citet{HarveyKoopman1992}, but see also \citet[section 3]{Koopman1993},  \citet{deJongPenzer1998} and \citet{Penzer2001} for discussions of using auxiliary residuals for detection of outliers and structural breaks. 

The \verb@MARSS()@ function will output the expected values of $x_t$ conditioned on the maximum-likelihood values of $q$, $r$, and $x_1$ and on the data ($y$ from $t=1$ to $T$).   In time-series literature, these are called the smoothed state estimates and they are output by the Kalman filter-smoother.  We will denote these smoothed estimates $x_t^T$ (and are \verb@xtT@ in the MARSS output). The time value in the superscript indicates the last data time point on which the estimate was conditioned (in this case, the state estimate is conditioned on data from $t=1$ to $t=T$). From these, we can compute the model predicted value of $y_t$, denoted or $\hat{y}_t^T$.  This is the predicted value of $y_t$ conditioned on $x_t^T$. 
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{split}
x_t^T &= \E[X_t|\hat{\theta}, y_1^T]\\
\hat{y}_t^T &= \E[Y_t|\hat{\theta}, x_t^T] \\
&= x_t^T + \E[w_t|\hat{\theta}, y_1^T] = x_t^T
\end{split}   
\label{eq:hatxy}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
where $\hat{\theta}$ are the maximum-likelihood estimates of the parameters.  The $\hat{y}_t^T$ equation comes directly from equation \ref{eq:random.walk.w.noise}.  This expectation is not conditioned on the data $y_1^T$, directly.  It is conditioned on $x_t^T$, which is conditioned on $y_1^T$. 

\subsection{Using observation residuals to detect outliers}
\index{residuals!model}\index{residuals!smoothations}The standardized smoothed observation (or model) residuals\footnote{also called smoothations in the literature to distinguish them from innovations, which are $\yy_t-\E[\YY_t|x_t^{t-1}]$. Notice that for innovations the expectation is conditioned on the data up to time $t-1$ while for smoothations, we condition on all the data.} are the difference between the data at time $t$ and the model fit at time $t$ conditioned on all the data and then standardized by the observation variance:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{split}
\hat{v}_t &= y_t - \hat{y}_t^T  \\
e_t &= \frac{1}{\sqrt{\var(\hat{v}_t)}} \hat{v}_t
\end{split}
 \label{eq:smoothations}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
These residuals should have (asymptotically) a t-distribution \citep[section 3]{KohnAnsley1989} and by looking at the residuals, we can identify potential outlier data points--or more accurately, we can identify data points that do not fit the model (Equation \ref{eq:random.walk.w.noise}).  The call \verb@MARSSresiduals(..., type="tT")@ will compute the smoothation (or auxilliary) residuals for a marssMLE object (output by a MARSS call).   \verb@MARSSresiduals()@ returns two types of standardized residuals (also called auxiliary residuals): Cholesky standardized residuals and marginal standardized residuals. We are using the latter here. The residuals are returned as a $n+m \times T$ matrix.  The first $n$ rows are the estimated $\vv_t$ standardized observation residuals and the next $m$ rows are the estimated $\ww_t$  standardized state residuals (discussed below). \verb@residuals(..., type="tT")@ will also return the smoothations but in a data frame. Here we use \verb@MARSSresiduals()@ which return them in a list of matrices. \index{functions!residuals}

<<Cs09_compute-resids, eval=TRUE, echo=TRUE>>=
resids.0 <- MARSSresiduals(kem.0, type = "tT")$mar.residuals
resids.1 <- MARSSresiduals(kem.1, type = "tT")$mar.residuals
resids.2 <- MARSSresiduals(kem.2, type = "tT")$mar.residuals
@

Figure \ref{fig:CS6.outliers} shows the observation residuals for the three models developed above.  We immediately see that model 0 (flat level) and model 1 (linear declining level) have problems because the residuals are all positive for the first part of the time series and then all negative.  The residuals should not be temporally correlated like that.  Model 2 with a stochastic level shows well-behaving residuals with low temporal correlation between $t$ and $t-1$.  Looking at the residuals for model 2, we see that there are a number of years with flow levels that appear to be outliers (are beyond the dashed level lines).

\begin{figure}[htp]
\begin{center}
<<Cs10_plotoutliertests, eval=TRUE, echo=FALSE, fig=TRUE>>=
library(Hmisc)
par(mfrow = c(3, 1), mar = c(3, 4, 1.5, 2))
x <- seq(tsp(Nile)[1], tsp(Nile)[2], tsp(Nile)[3])
plot(x, resids.0[1, ],
  ylab = "Std. residuals", xlab = "", type = "l",
  ylim = c(-4, 4), xaxp = c(1870, 1970, 10), bty = "L"
)
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97, 0), lty = 2)
title("model 0--flat level")

plot(x, resids.1[1, ],
  ylab = "Std. residuals", xlab = "", type = "l",
  ylim = c(-4, 4), xaxp = c(1870, 1970, 10), bty = "L"
)
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97, 0), lty = 2)
title("model 1--linearly declining level")

plot(x, resids.2[1, ],
  ylab = "Std. residuals", xlab = "", type = "l",
  ylim = c(-4, 4), xaxp = c(1870, 1970, 10), bty = "L"
)
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97, 0), lty = 2)
title("model 2--stochastic level")
@
\end{center}
\caption{The marginal standardized observation residuals from models 0, 1, and 2.  These residuals are the standardized $\hat{v}_t$.  The dashed lines are the 95\% CIs for a $t$-distribution.}
\label{fig:CS6.outliers}
\end{figure}

\subsection{Detecting sudden level changes}
\index{residuals!state}
The standardized smoothed state residuals ($f_t$ below) are the difference between the estimated state at time $t$ and the estimated state at time $t-1$ conditioned on all the data and then standardized by the standard deviation:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{split}
\hat{w}_t &= x_t^T - x_{t-1}^T   \\
f_t &= \frac{1}{\sqrt{\var(\hat{w}_t)}}\hat{w}_t
\end{split}
 \label{eq:stateresids}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
These state residuals do not show simple changes in the average level; $x_t$ is clearly changing in Figure \ref{fig:CS6.fits}, bottom panel.  Instead we are looking for ``breaks" or sudden changes in the level.  The bottom panel of Figure \ref{fig:CS6.levelchanges} shows the standardized state residuals ($f_t$).  This shows, as we can see by eye, the average flow level in the Nile appears to have suddenly changed around the turn of the century when the first Aswan dam was built.  The top panel shows the standardized observation residuals for comparison.  

\begin{figure}[htp]
\begin{center}
<<Cs11_plotresids, eval=TRUE, echo=FALSE, fig=TRUE>>=
par(mfrow = c(2, 1), mar = c(4, 3, 2, 1))
x <- seq(tsp(Nile)[1], tsp(Nile)[2], tsp(Nile)[3])
plot(x, resids.2[1, ], ylab = "", xlab = "", type = "l", ylim = c(-4, 4), xaxp = c(1870, 1970, 10))
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97), lty = 2)
title("test for outliers")

plot(x, resids.2[2, ], ylab = "", xlab = "", type = "l", ylim = c(-4, 4), xaxp = c(1870, 1970, 10))
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97), lty = 2)
title("test for level changes")
mtext("Standardized residuals", side = 2, outer = TRUE, line = -1)
@
\end{center}
\caption{Top panel, the marginal standardized observation residuals.  Bottom panel, the standardized state residuals.  This replicates Figure 12 in Koopman et al. (1999).}
\label{fig:CS6.levelchanges}
\end{figure}

\subsection{Detecting changes in the drift parameter in a random walk model}
\index{structural ts model!trend}
The model of a random walk with a fixed $u$ drift term is: 
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
y_t = x_t+v_t \text{ where } v_t \sim \N(0,r)  \\
x_t = x_{t-1}+u+w_t \text{ where } w_t \sim \N(0,q) \\
x_0 = \pi 
\end{gathered}   
\label{eq:random.walk.w.drift}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
Same as we did for the level, we can model the drift as a random walk and explore whether $u_t$ has changed over time or whether it has experienced sudden breaks. The stochastic level and trend model is
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
y_t = x_t + v_t \text{where } v_t \sim \N(0,r)  \\
x_t = x_{t-1} + u_{t-1} + w_t \text{ where } w_t \sim \N(0,q) \\
u_t = u_{t-1} +  z_t \text{ where } z_t \sim \N(0,p) \\
x_0 = \pi_x \text{ and }  u_0 = \pi_u
\end{gathered}\label{eq:stochastic.slope}
\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~

Write the model in MARSS form:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
y_t = \begin{bmatrix}1&0\end{bmatrix}\begin{bmatrix}x_t\\ u_t\end{bmatrix} + v_t \\
\begin{bmatrix}x_t\\ u_t\end{bmatrix}
= \begin{bmatrix}1&1\\0&1\end{bmatrix}
\begin{bmatrix}x_{t-1}\\ u_{t-1}\end{bmatrix} 
+ \begin{bmatrix}w_t\\ z_t\end{bmatrix} \text{ where }
\begin{bmatrix}v_t\\ z_t \end{bmatrix} \sim 
\MVN\bigg(0, \begin{bmatrix}q&0\\0&p \end{bmatrix}\bigg)
\end{gathered}\label{eq:marss.stochastic.slope}
\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~

The model is then:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
y_t = \ZZ\xx + \aa + v_t \\
\xx_t=\BB\xx_{t-1}+\uu+ \ww_t\\
\\
\ZZ= \begin{bmatrix}1&0\end{bmatrix} \text{  }
\aa= \begin{bmatrix}0\end{bmatrix} \text{  }
\RR= \begin{bmatrix}r\end{bmatrix} \\
\BB= \begin{bmatrix}1&1\\0&1\end{bmatrix} \text{  }
\uu= \begin{bmatrix}0\\0\end{bmatrix} \text{  }
\QQ= \begin{bmatrix}q&0\\0&p \end{bmatrix} \text{  }
\xx_0= \begin{bmatrix}\pi_x\\ \pi_u \end{bmatrix}\\
\end{gathered} \label{eq:marss.stochastic.slope2}
 \end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
We then write the model list as:
<<mod-nile-3>>=
mod.nile.3 <- list(
  Z = matrix(c(1, 0), 1, 2), A = matrix(0), R = matrix("r"),
  B = matrix(c(1, 0, 1, 1), 2, 2), U = matrix(0, 2, 1),
  Q = matrix(list("q", 0, 0, "p"), 2, 2),
  x0 = matrix(c("x", "u"), 2, 1)
)
@


This model takes a long time to fit with the EM algorithm\footnote{Normally this type of model is fit with a fixed diffuse initial condition which makes the fitting much faster. See the chapter on Structural time series models}.  We could run the EM algorithm a long time, but there is a quicker trick in this case.  We will run the EM algorithm for a few iterations and stop before convergence.  Then we will use the fit from the EM algorithm as the initial condition for the faster BFGS algorithm for the final approach to the maximum-likelihood:
<<fit-mod3, echo=TRUE>>=
model <- mod.nile.3
kem.3 <- MARSS(dat,
  model = model, inits = list(x0 = matrix(c(1000, -4), 2, 1)),
  control = list(maxit = 20), silent = TRUE
)
kem.3 <- MARSS(dat,
  model = model, inits = kem.3,
  method = "BFGS", silent = TRUE
)
summary(kem.3)
@


The Nile data is not a good example since the variance for the slope is close to zero so the residual line is just a flat 0 (see value for \verb@Q.p@). Let's run the same model on the \verb@WWWusage@ dataset (Figure \ref{fig:CS6.WWWdata}).

\begin{figure}[htp]
\begin{center}
<<plotslopetests-nile, echo=FALSE, fig=TRUE, height=4>>=
plot(WWWusage, xlab = "")
@
\end{center}
\caption{The WWWusage data set.}
\label{fig:CS6.WWWdata}
\end{figure}


<<fit-mod-www, echo=TRUE>>=
dat <- as.vector(WWWusage)
kem.3 <- MARSS(dat,
  model = model, inits = list(x0 = matrix(0, 2, 1)),
  control = list(maxit = 20), silent = TRUE
)
kem.3 <- MARSS(dat,
  model = model, inits = kem.3,
  method = "BFGS", silent = TRUE
)
summary(kem.3)
@

Figure \ref{fig:CS6.fig4} shows the standardized residuals for the $u$, which is the 2nd state in $\xx$. There appears to be unusually large changes in the trend around year 25. The other changes in the trend are consistent with a random walk; i.e., the trend changes but only the rapid change near year 25 is inconsistent with the estimated trend random walk.

\begin{figure}[htp]
\begin{center}
<<plotslopetests-www, echo=FALSE, fig=TRUE>>=
library(Hmisc)
resids <- MARSSresiduals(kem.3, type = "tT")$mar.residuals
x <- seq(tsp(WWWusage)[1], tsp(WWWusage)[2], tsp(WWWusage)[3])
plot(x, resids[3, ],
  ylab = "Mar. residuals", xlab = "", type = "l", ylim = c(-4, 4),
  xaxp = c(tsp(WWWusage)[1] - 1, tsp(WWWusage)[2], 10)
)
minor.tick(nx = 10, ny = 0, tick.ratio = .3)
abline(h = c(1.97, -1.97), lty = 2)
abline(h = 0)
title("test for slope changes")
@
\end{center}
\caption{The marginal standardized residuals for slope changes for the WWWusage model.}
\label{fig:CS6.fig4}
\end{figure}

\section{Discussion}

This chapter shows the basic strategy for doing shock detection sensu Harvey et al. using standardized residuals. This was illustrated with stochastic level and trend models. Stochastic level and trend models are also called Structural Time Series models. You can find more examples of these models in Chapter \ref{chap:structts}.

<<Reset, echo=FALSE>>=
options(prompt = "> ", continue = "+ ")
options(width = 120)
@
