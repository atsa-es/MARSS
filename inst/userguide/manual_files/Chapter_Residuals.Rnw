\SweaveOpts{keep.source=TRUE, prefix.string=./figures/Interval-, eps=FALSE, split=TRUE}
<<RUNFIRST, echo=FALSE, include.source=FALSE>>=
options(prompt = " ", continue = " ", width = 60)
@
<<Covar_sec0_required_libraries, echo=FALSE>>=
library(MARSS)
@
\chapter{MARSS Intervals and Residuals}
\label{chap:intervals}
\chaptermark{Intervals and Residuals}
%Add footnote with instructions for getting code
\blfootnote{Type \texttt{RShowDoc("Chapter\_Intervals.R",package="MARSS")} at the R command line to open a file with all the code for the examples in this chapter.}

\section{MARSS uncertainty specification}
\index{residuals}

There are a variety of types of outputs and intervals for MARSS models. This chapter summarizes them and tells you which function to use to get the output you want.

When looking at estimates and intervals for $\xx$ and $\yy$, keep in mind that the MARSS parameters are always fixed. The uncertainty arise because $\xx$ and $\yy$ are stochastic not because of uncertainty in the parameter estimates. The latter type of uncertainty arises because we could have collected different data and those data would give us different parameter estimates. If you looked at the intervals on model fits (a regression line say) from a classic linear regression those intervals reflect parameter uncertainty. The intervals on $\xx$ (states) and $\yy$ (observations) in a MARSS model are fundamentally different. $\XX$ is stochastic and unobserved. $\YY$ is stochastic and observed (at least partially).

\itemize{
\item  If you want the estimate of $\xx$ conditioned on all the data 1 to $T$, then use \verb@tsSmooth.marssMLE()@ with \verb@type="xtT"@. This gives $\E[\XX|all data]$.  This is the states estimates from the Kalman smoother. You can also output these with \verb@MARSSkf()@. The confidence interval is based on  $\var[\XX|all data]$, the conditional variance of $\XX$. That variance is \verb@VtT[,,t]@.

\item  If you want the estimate of $\xx$ conditioned on the data up to $t-1$, then use \verb@tsSmooth.marssMLE@ with \verb@type="xtt1"@. This is the one step ahead prediction, $\BB \xx_{t-1} + \uu$, and its variance. \verb@tidy.marssMLE@ returns a prediction interval based on the variance  \verb@Vtt1[,,t]=B Vtt[,,t-1] B^T + Q@. If you wanted the confidence interval on the expected value, that would use the variance \verb@B Vtt[,,t-1] B^T@. \code{\link{fitted.marssMLE}} will return that.

\item  If you want the estimate of y conditioned on all the data, then use \verb@tsSmooth.marssMLE@ with \verb@type="ytT"@. This gives $\E[\YY|\yy]$ and if you have no missing data, $\E[\YY|data] = \yy$ so you will just be returning your data. The confidence intervals will also be 0. For missing $\yy$ values, you will see prediction intervals since \verb@tsSmooth.marssMLE@ returns intervals based on $\var[\YY|\yy]$.
  
\item  If you want the estimate of $\yy$ conditioned on the data up to $t-1$, then use \verb@fitted.marssMLE@ with \verb@type="ytt1"@. This is the one step ahead prediction, $\ZZ \xx_t^{t-1} + \aa$, and its variance. The prediction interval is based on the variance \verb@Z Vtt1[,,t] Z^T + R@. The confidence interval on the expected value of the prediction, that would use \verb@Z Vtt1[,,t] Z^T@.
}

\section{One step ahead predictions} 

Use \verb@conditioning="t-1"@ for the one-step-ahead predictions of $\yy_t$, using only data up to $t-1$. Because the one-step-ahead predictions do not include $\yy_t$ for calculation, you can use your data to evaluate the intervals. Thus in this case (only) it would make sense to plot your data on top of the prediction intervals. But in general use \verb@residuals.marssMLE@ when you want statistics (such as intervals) associated with your observed data.



\section{fitted Y(t)}\index{fitted}

The fitted values of $\YY_t$ is the expected value of the right side of the $\yy_t$ equation WITHOUT the $\vv_t$. Use \verb@fitted.marssMLE@ and \verb@fitted.marssMLE@ to get the fitted values, their residuals, and their residual variances (for outlier analysis).

\section{Residual intervals}

For residuals analysis (outlier detection), you want to use the "residual" intervals provided with \verb@residuals.marssMLE@. These are are the quantiles for the model residuals for data that were used to fit the model (and estimate xtT).  The residuals intervals are also what you want to evaluate data that you leave out, for example for a leave-one-out-cross-validation.

<<label=resids, keep.source=TRUE>>=
dat <- t(harborSealWA)
dat <- dat[2, ] # remove the year row
Q <- array(c(rep(.02, 11), rep(.01, 11)), dim = c(1, 1, 22))
kem <- MARSS(dat, model = list(Q = Q))
# returns a data.frame
harvey.resids <- residuals(kem, type = "tT", Harvey = TRUE)
holmes.resids <- residuals(kem, type = "tT", Harvey = FALSE)
identical(harvey.resids, holmes.resids)
# returns a matrix with various variances
harvey.resids <- MARSSresiduals(kem, type = "tT", Harvey = TRUE)
holmes.resids <- MARSSresiduals(kem, type = "tT", Harvey = FALSE)
for (i in names(holmes.resids)) cat(i, all(na.omit(as.vector(harvey.resids[[i]] - holmes.resids[[i]])) < sqrt(.Machine$double.eps)), "\n")
@

\subsection{Structural time series models}

\subsubsection{Level model}

The basic stochastic level ($m$) model fit by \verb@stats::StructTS()@ is

\begin{equation}\label{eqn:struct.ts.y}
y_t = m_t+v_t \text{ where } v_t \sim \N(0,\epsilon)  \\
\end{equation}

where

\begin{equation}\label{eqn:struct.ts.x}
m_t = m_{t-1}+ w_t \text{ where } w_t \sim \N(0,\xi)
\end{equation}

The initial conditions assumption used to fit the state-space in the \verb@StructTS()@ function is the following and this must be used in order to replicate the output. The initial condition at $t=0$ for $m$ is stochastic with fixed mean equal to $y_1$ and variance equal to 1000 times the variance of the data.

\begin{equation}\label{eqn:struct.ts.x0}
m_0 \sim \N(y_1, 10000\times\var(y))
\end{equation}

Here the model is fit to 20 time steps of tree ring data. \verb@fit1@ is the \verb@StructTS()@ output, 
\verb@fit2@ shows how to form the model as a MARSS model and fits using the \verb@fit1@ estimated values, \verb@fit3@ fits the model with \verb@MARSS()@ using BFGS (though slightly different algorithm), and \verb@fit4@ fits the model using EM. \verb@fit3@ and \verb@fit4@ are slightly different than \verb@fit1@ because the optimization algorithm is a hill-climbing algorithm for all these fits and stops at slightly different points on the likelihood 'hill'.

Another difference with \verb@StructTS()@ is that the reported fitted level (the $x$ state estimate) is the estimate of the state conditioned on the data up to $t$ not $T$. In MARSS, the state estimate (in the \verb@states@ element) is reported conditioned on all the data (up to $T$). To compare the outputs, we need to use \verb@MARSSkfss()@ (the classic Kalman filter as opposed to the faster one that avoids matrix inversion) to get \verb@xtt$ (the estimate of $x$ conditioned on data up to $t$).

<<label=structTS.level, keep.source=TRUE>>=
y <- window(treering, start = 0, end = 20)
vy <- var(y, na.rm = TRUE) / 100

fit1 <- StructTS(y, type = "level")
mod.list <- list(
  x0 = matrix(y[1]), U = "zero", tinitx = 0,
  Q = matrix(fit1$coef[1]), R = matrix(fit1$coef[2]),
  V0 = matrix(1e+06 * vy)
)
fit2 <- MARSS(as.vector(y), model = mod.list)
fit2$kf <- MARSSkfss(fit2)
mod.list <- list(x0 = matrix(y[1]), U = "zero", tinitx = 0, V0 = matrix(1e+06 * vx))
fit3 <- MARSS(as.vector(y), model = mod.list, method = "BFGS")
fit3$kf <- MARSSkfss(fit3)
fit4 <- MARSS(as.vector(y), model = mod.list)
fit4$kf <- MARSSkfss(fit4)
cbind(fit1$fitted, fit2$kf$xtt[1, ], fit3$kf$xtt[1, ], fit4$kf$xtt[1, ])[1:5, ]
@

<<label=plot.structTS, echo=FALSE, keep.source=TRUE, fig=TRUE, width=6, height=6>>=
library(tidyr)
df1 <- as.data.frame(fit1$fitted)
vars <- colnames(df1)
df2 <- as.data.frame(t(fit3$kf$xtt))
colnames(df2) <- vars
df1$model <- "StructTS"
df2$model <- "MARSS"
df1$t <- as.vector(time(fit1$fitted))
df2$t <- df1$t
df <- rbind(df1, df2)
df <- df %>% pivot_longer(all_of(vars))
ggplot(df, aes(x = t, y = value)) +
  geom_line() +
  facet_wrap(~model)
@

\subsubsection{Level plus trend model}

The basic stochastic level ($m$) and trend ($n$) model fit by \verb@stats::StructTS()@ is

\begin{equation}\label{eqn:struct.ts.y}
y_t = m_t+v_t \text{ where } v_t \sim \N(0,\epsilon)  \\
\end{equation}

where

\begin{equation}\label{eqn:struct.ts.x}
\begin{bmatrix}
m\\
n
\end{bmatrix}_t = \begin{bmatrix}
1&1\\
0&1
\end{bmatrix}\begin{bmatrix}
m\\
n
\end{bmatrix}_{t-1}+\ww_t \text{ where } \ww_t \sim \MVN\left(0,\begin{bmatrix}
\xi&0\\
0&\zeta
\end{bmatrix}\right) \\
\end{equation}


The initial conditions assumption used to fit the state-space in the \verb@StructTS()@ function for the level plus trend model is the following where $\sigma^2$ is the variance in the data ($\var(y)$):

\begin{equation}\label{eqn:struct.leveltrend.x0}
\begin{bmatrix}
m\\
n
\end{bmatrix}_0 \sim \MVN\left(\begin{bmatrix}
y_1\\
0
\end{bmatrix},
\begin{bmatrix}
10000 \sigma^2& 10000 \sigma^2\\
10000 \sigma^2& 10000 \sigma^2
\end{bmatrix}\right) \\
\end{equation}

Because \verb@MARSS()@ does an inversion of \verb@V0@ (part of code to force positive definite matrices and deal with degenerate models with 0s on diagonals of $\QQ$ or $\RR$), the \verb@V0$ used in \verb@StructTS@ needs to be made positive definite for \verb@MARSS()@. This is done by adding a small value to the diagonal.

<<label=structTS.leveltrend, keep.source=TRUE>>=
y <- log10(forecast:::subset.ts(UKgas, quarter = 2))
vy <- var(y, na.rm = TRUE) / 100

fit1 <- StructTS(y, type = "trend")

B <- matrix(c(1, 0, 1, 1), 2, 2)
Z <- matrix(c(1, 0), 1, 2)

mod.list <- list(
  x0 = matrix(c(y[1], 0), 2, 1), U = "zero", tinitx = 0,
  Q = diag(fit1$coef[1:2]), R = matrix(fit1$coef[3]),
  V0 = matrix(1e+06 * vy, 2, 2), Z = Z, B = B
)
fit2 <- MARSS(as.vector(y), model = mod.list, fit = FALSE, control = list(trace = -1))
fit2$par <- fit2$start
fit2$kf <- MARSSkfss(fit2)
mod.list <- list(
  x0 = matrix(c(y[1], 0), 2, 1), U = "zero", tinitx = 0,
  Q = "diagonal and unequal",
  V0 = matrix(1e+06 * vy, 2, 2) + diag(1e-10, 2), Z = Z, B = B
)
fit3 <- MARSS(as.vector(y), model = mod.list, method = "BFGS")
fit3$kf <- MARSSkfss(fit3)
fit4 <- MARSS(as.vector(y), model = mod.list)
fit4$kf <- MARSSkfss(fit4)
data.frame(
  structTS = fit1$fitted[, 1], fit2 = fit2$kf$xtt[1, ],
  fit3 = fit3$kf$xtt[1, ], fit4 = fit4$kf$xtt[1, ]
)[1:5, ]
@

<<label=plot.structTS.leveltrend, echo=FALSE, keep.source=TRUE, fig=TRUE, width=6, height=6>>=
library(tidyr)
df1 <- as.data.frame(fit1$fitted)
vars <- colnames(df1)
df2 <- as.data.frame(t(fit3$kf$xtt))
colnames(df2) <- vars
df1$model <- "StructTS"
df2$model <- "MARSS"
df1$t <- as.vector(time(fit1$fitted))
df2$t <- df1$t
df <- rbind(df1, df2)
df <- df %>% pivot_longer(all_of(vars))
ggplot(df, aes(x = t, y = value, color = model, linetype = model, shape = model)) +
  geom_line() +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  scale_linetype_manual("model", values = c(1, 0)) +
  scale_shape_manual("model", values = c(NA, 16))
@

\subsubsection{Seasonal or BSM model}

The seasonal model fit by \verb@stats::StructTS()@ is the level plus trend model with an additional seasonal component $s_t$.

\begin{equation}\label{eqn:struct.bsm.y}
y_t = m_t+s_t+v_t \text{ where } v_t \sim \N(0,\epsilon)  \\
\end{equation}

and 

\begin{equation}\label{eqn:struct.bsm.y}
s_t = -s_{t-1}-\dots-s_{t-f+1}+v_t \text{ where } v_t \sim \N(0,\epsilon)  \\
\end{equation}

where $f$ is the frequency of the seasonality. So for quarterly data, $f=4$ and the $s_t$ model is

\begin{equation}\label{eqn:struct.bsm.y}
s_t = -s_{t-1}-s{t-2}-s_{t-3}+v_t \text{ where } v_t \sim \N(0,\epsilon)  \\
\end{equation}


Written in matrix form the model for a quarterly seasonality is the following. $s$ is the seasonality term while $s_1$ and $s_2$ are just keeping track of $s_{t-2}$ and $s_{t-3}$.

\begin{equation}\label{eqn:struct.bsm.y.matrix}
y_t = \begin{bmatrix}1&0&1&0&0\end{bmatrix}\begin{bmatrix}
m\\
n \\
s\\
s_1\\
s_2
\end{bmatrix}_t + v_t
\end{equation}

and 

\begin{equation}\label{eqn:struct.bsm.x}
\begin{bmatrix}
m\\
n \\
s\\
s_2\\
s_3
\end{bmatrix}_t = \begin{bmatrix}
1&1&0&0&0\\
0&1&0&0&0\\
0&0&-1&-1&-1\\
0&0&1&0&0\\
0&0&0&1&0
\end{bmatrix}\begin{bmatrix}
m\\
n\\
s\\
s_2\\
s_3
\end{bmatrix}_{t-1}+\ww_t \text{ where } \ww_t \sim \MVN\left(0,\begin{bmatrix}
\xi&0&0&0&0\\
0&\zeta&0&0&0\\
0&0&\sigma^2_w&0&0\\
0&0&0&0&0\\
0&0&0&0&0
\end{bmatrix}\right) \\
\end{equation}


The initial conditions assumption is the following where again $\sigma^2$ is the variance in the data ($\var(y)$):

\begin{equation}\label{eqn:struct.leveltrend.x0}
\begin{bmatrix}
m\\
n\\
s\\
s_2\\
s_3
\end{bmatrix}_0 \sim \MVN\left(\begin{bmatrix}
y_1\\0\\0\\0\\0
\end{bmatrix},
\begin{bmatrix}
1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2\\
1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2\\
1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2\\
1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2\\
1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2& 1e4 \sigma^2
\end{bmatrix}\right)
\end{equation}

Let's see an example with the UKgas data set used in \verb@?StructTS@.

<<label=fit.structTS.bsm, keep.source=TRUE>>=
y <- log10(UKgas)
fit1 <- StructTS(y, type = "BSM")
@

<<label=makeB>>=
makeB <- function(nf) {
  B <- matrix(0, nf + 1L, nf + 1L)
  B[1L:2L, 1L:2L] <- c(1, 0, 1, 1)
  B[3L, ] <- c(0, 0, rep(-1, nf - 1L))
  if (nf >= 3L) {
    ind <- 3:nf
    B[cbind(ind + 1L, ind)] <- 1
  }
  return(B)
}
@

<<label=fit.structTS.bsm.marss, keep.source=TRUE>>=
nf <- frequency(y)
B <- makeB(nf)
Z <- matrix(c(1, 0, 1, rep(0, nf - 2L)), 1, nf + 1)

Q <- ldiag(list("xi", "zeta", "s2", 0, 0))
mod.list <- list(
  x0 = matrix(c(y[1], rep(0, nf)), ncol = 1), U = "zero", A = "zero", tinitx = 0,
  Q = Q, V0 = matrix(1e+06 * vy, nf + 1, nf + 1) + diag(1e-10, nf + 1),
  Z = Z, B = B
)
fit3 <- MARSS(as.vector(y), model = mod.list, method = "BFGS")
fit3$kf <- MARSSkfss(fit3)
fit4 <- MARSS(as.vector(y), model = mod.list)
fit4$kf <- MARSSkfss(fit4)
data.frame(
  structTS = fit1$fitted[, 1],
  fit3 = fit3$kf$xtt[1, ], fit4 = fit4$kf$xtt[1, ]
)[1:5, ]
@

<<label=plot.structTS.leveltrend, echo=FALSE, keep.source=TRUE, fig=TRUE, width=6, height=6>>=
library(tidyr)
df1 <- as.data.frame(fit1$fitted)
vars <- colnames(df1)
df2 <- as.data.frame(t(fit3$kf$xtt)[, 1:3])
colnames(df2) <- vars
df3 <- as.data.frame(t(fit4$kf$xtt)[, 1:3])
colnames(df3) <- vars
df1$model <- "StructTS"
df2$model <- "MARSS BFGS"
df3$model <- "MARSS EM"
df1$t <- as.vector(time(fit1$fitted))
df1$Qtr <- as.vector(cycle(fit1$fitted))
df2$t <- df1$t
df2$Qtr <- df1$Qtr
df3$t <- df1$t
df3$Qtr <- df1$Qtr
df <- rbind(df1, df2, df3)
df <- subset(df, Qtr == 1) %>% pivot_longer(all_of(vars))
ggplot(df, aes(x = t, y = value, color = model, linetype = model, shape = model)) +
  geom_line() +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  scale_linetype_manual("model", values = c(0, 0, 1)) +
  scale_shape_manual("model", values = c(16, 16, NA))
@


\section{Leave-one-out analysis} 

The one-step-ahead prediction intervals are not what you want if you left some of your data out and want to evaluate the model residuals for the left-out-data. The residuals intervals are also what you want for this case (with the left-out-data set to NA).

\section{Prediction intervals for new data} 

The one-step-ahead prediction intervals are also not what you want if you want to compute intervals for data during 1 to $T$ that you didn't collect (so not in the future but contemporaneous with your data).  To compute prediction intervals for new data within 1 to $T$ (so not forecasts past $T$), you need to decide what you mean by 'new' and how these new data at time $t$ relate to existing data at time $t$. Are the new data are i.i.d relative to the old data? So if you made an R matrix, it would be diagonal with the same value on the diagonal. Or are they missing data which might have a different variance and be correlated with the old data. In this case the $\RR$ matrix might not be diagonal with one value on the diagonal.


<<reset, echo=FALSE>>=
options(prompt = "> ", continue = " +", width = 120)
@
